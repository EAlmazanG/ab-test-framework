{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import re\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import analysis\n",
    "from src import framework\n",
    "from src import ab_tests\n",
    "from src.framework import print_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(analysis)\n",
    "importlib.reload(framework)\n",
    "importlib.reload(ab_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOURCES INGESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "file_name = '.csv'\n",
    "df_raw = pd.read_csv('../data/' + file_name)\n",
    "display(df_raw.head(5))\n",
    "\n",
    "# Make a copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Check dtypes\n",
    "print_title('INITIAL DATA TYPES')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns = ['...', '...', '...']\n",
    "int64_columns = ['...', '...', '...']\n",
    "float64_columns = ['...', '...', '...']\n",
    "str_columns = ['...', '...', '...']\n",
    "\n",
    "# Basic data conversion\n",
    "df = framework.format_columns(df, datetime_columns, int64_columns, float64_columns, str_columns)\n",
    "\n",
    "# Check dtypes\n",
    "print_title('CONVERTED DATA TYPES')\n",
    "print(df.dtypes)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_column = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick checks on data\n",
    "print_title('DF INFO')\n",
    "display(df.info())\n",
    "\n",
    "print_title('DF DESCRIBE')\n",
    "display(df.describe())\n",
    "\n",
    "# Check distribution of variants\n",
    "print_title('VARIANT DISTRIBUTION')\n",
    "display(df[variant_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and drop duplicates in the entire DataFrame\n",
    "duplicated_rows = df.duplicated().sum()\n",
    "print('# of duplicated rows: ', duplicated_rows)\n",
    "\n",
    "if duplicated_rows > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print('Duplicates in the DataFrame removed.')\n",
    "else:\n",
    "    print('No duplicates in the DataFrame found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key_column = '...'\n",
    "timestamp_column = ''\n",
    "\n",
    "# Check for duplicates in the unique columns\n",
    "duplicated_rows = df[df[primary_key_column].duplicated(keep=False)]\n",
    "print(f'# of duplicated on {primary_key_column} column: {duplicated_rows[primary_key_column].nunique()}')\n",
    "\n",
    "if not duplicated_rows.empty:\n",
    "    print(f'Duplicated {primary_key_column} and their rows:')\n",
    "    display(duplicated_rows.sort_values(by = primary_key_column))\n",
    "\n",
    "    # Keep only the first following timestamp column order\n",
    "    if timestamp_column == '':\n",
    "        df = df.drop_duplicates(subset=primary_key_column, keep='last')\n",
    "        print('Kept the most recent row for each duplicated' +  primary_key_column)\n",
    "    else:\n",
    "        df = df.sort_values(timestamp_column).drop_duplicates(subset=primary_key_column, keep='last')\n",
    "        print('Kept the most recent row for each duplicated ' + primary_key_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print_title('NUMBER OF NULL VALUES')\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null columns\n",
    "df['...'] = df['...'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics, use metric_cnt_ or metric_cvr_\n",
    "df['metric_cnt_...'] = df['...']\n",
    "df['metric_cvr...'] = df['...'].apply(lambda x: 1 if x > 0 else 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEGMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICS AND CONFIG SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select metrics and columns involved in the test\n",
    "primary_key_column = '...'\n",
    "metric_column = '...'\n",
    "variant_column = '...'\n",
    "segment_column = '...'\n",
    "\n",
    "columns_selection_df = df[[primary_key_column, variant_column, segment_column, metric_column]]\n",
    "metric_type = (\n",
    "    'continuous' if metric_column.startswith('metric_cnt_') else\n",
    "    'proportion' if metric_column.startswith('metric_cvr_') else\n",
    "    None\n",
    ")\n",
    "outliers_filtered_df, is_strong_outlier_effect = analysis.remove_outliers(columns_selection_df, metric_column, 1)\n",
    "\n",
    "# Filter outliers:\n",
    "filter_outliers = False\n",
    "\n",
    "if filter_outliers:\n",
    "    selected_df = outliers_filtered_df.copy()\n",
    "else:\n",
    "    selected_df = columns_selection_df.copy()\n",
    "\n",
    "display(selected_df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA ANALYSIS AND STATISTICAL TESTING BY SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    selected_df = framework.add_segment_column(selected_df, num_segments=4)\n",
    "display(selected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = selected_df[segment_column].unique()\n",
    "\n",
    "for segment in segments:\n",
    "    print_title('SEGMENT: ' + str(segment), 160, '=')\n",
    "    print_title('DATA ANALYSIS', 130, ':')\n",
    "    segment_df = selected_df[selected_df[segment_column] == segment]\n",
    "\n",
    "    ### NUMBER OF VARIANTES\n",
    "    num_variants = segment_df[variant_column].nunique()\n",
    "\n",
    "    print(f\"Number of Variants: {num_variants}\")\n",
    "    print(f\"Variants: {segment_df[variant_column].unique()}\")\n",
    "\n",
    "    ### SAMPLE SIZES\n",
    "    sample_sizes = segment_df[variant_column].value_counts()\n",
    "    print(\"Sample sizes per variant:\")\n",
    "    print(sample_sizes)\n",
    "\n",
    "    variant_proportion = sample_sizes / sample_sizes.sum()\n",
    "    print(\"\\nProportion per variant:\")\n",
    "    print(variant_proportion)\n",
    "\n",
    "    variant_ratio = sample_sizes.max() / sample_sizes.min()\n",
    "    print(f\"\\nVariant Ratio (N = max/min): {variant_ratio:.2f}\")\n",
    "\n",
    "    ### SAMPLE DISTRIBUTION\n",
    "    sns.set_style(\"white\")\n",
    "    print_title('NORMAL DISTRIBUTION VISUAL ANALYSIS', 100)\n",
    "    analysis.plot_qq(segment_df, variant_column, metric_column)\n",
    "    analysis.plot_histogram_kde(segment_df, variant_column, metric_column)\n",
    "    analysis.plot_violin(segment_df, variant_column, metric_column)\n",
    "    analysis.plot_combined_kde(segment_df, variant_column, metric_column)\n",
    "\n",
    "    print_title('NORMAL DISTRIBUTION TEST RESULTS', 100)\n",
    "    distribution_results = analysis.calculate_distribution(segment_df, variant_column, metric_column)\n",
    "\n",
    "    is_normal_distribution = analysis.set_normal_distribution_flag(distribution_results, alpha=0.05)\n",
    "    print(f'\\nUSE NORMAL DISTRIBUTION TESTS: {is_normal_distribution}')\n",
    "\n",
    "    ### SAMPLE VARIANCES\n",
    "    print_title('VARIANCE TEST RESULTS', 100)\n",
    "    variance_results = analysis.calculate_variance_analysis(segment_df, variant_column, metric_column)\n",
    "\n",
    "    is_equal_variance = analysis.set_equal_variance_flag(variance_results, alpha=0.05)\n",
    "    print(f'\\nUSE EQUAL VARIANCE TESTS: {is_equal_variance}')\n",
    "\n",
    "    ## STATISICAL TESTING\n",
    "    print_title('STATISICAL TESTING', 130, ':')\n",
    "    ### TESTS AND TECHNIQUES SELECTION\n",
    "    print_title('TEST VARIABLES', 100)\n",
    "    ab_test_config = ab_tests.configure_ab_test(metric_type, is_equal_variance, is_normal_distribution, num_variants, variant_ratio, sample_sizes, is_strong_outlier_effect)\n",
    "    print('\\n')\n",
    "    print_title('TEST SELECTION', 100)\n",
    "    print({key: value for key, value in ab_test_config.items() if value})\n",
    "\n",
    "    ### UNBALANCE DATA\n",
    "    segment_df = ab_tests.resample_data(segment_df, ab_test_config, variant_column)\n",
    "\n",
    "    ### TESTS\n",
    "    print_title('TEST RESULTS', 100)\n",
    "    standardized_results = ab_tests.run_complete_ab_test(ab_test_config, selected_df, variant_column, metric_column, num_variants, alpha = 0.05)\n",
    "    display(standardized_results)\n",
    "\n",
    "    print_title('TEST SELECTION', 100)\n",
    "    print({key: value for key, value in ab_test_config.items() if value})\n",
    "\n",
    "    framework.plot_distributions(selected_df, variant_column, metric_column, 0.05)\n",
    "\n",
    "    ### ADDITIONAL TECHNIQUES\n",
    "    print_title('ADDITIONAL TECHNIQUES', 100)\n",
    "    additional_tests_results = ab_tests.apply_additional_tests(ab_test_config, selected_df, variant_column, metric_column)\n",
    "    display(additional_tests_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERACTIONS TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interaction Tests, if discrepancies between segments\n",
    "use_anova_interaction_test_segmentation = False # to test interaction effect between variant and segment, continuous, normal\n",
    "use_welch_anova_interaction_test_segmentation = False # to test interaction effect between variant and segment, continuous, normal, can unbalanced\n",
    "use_kruskal_wallis_interaction_test_segmentation = False # to test interaction effect between variant and segment, continuous, not normal\n",
    "use_logistic_regression_interaction_test_segmentation = False # to test interaction effect for proportions, equivalent to ANOVA for categorical data\n",
    "# if true, post hoc with tukey, games howell or dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_tests = ab_tests.select_interaction_test(selected_df, variant_column, metric_column, segment_column, metric_type)\n",
    "\n",
    "print(interaction_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_results = ab_tests.run_interaction_tests( selected_df, variant_column, metric_column, segment_column, interaction_tests)\n",
    "\n",
    "for test, result in interaction_results.items():\n",
    "    print(f\"\\n{test}:\\n\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
