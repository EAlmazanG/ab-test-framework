{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_title(title, line_length = 60, symbol = '-'):\n",
    "    separator = symbol * ((line_length - len(title) - 2) // 2)\n",
    "    print(f\"{separator} {title} {separator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT DESIGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOURCES INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOURCES INGESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "file_name = 'ab_test_example_3.csv'\n",
    "df_raw = pd.read_csv('../data/' + file_name)\n",
    "display(df_raw.head(5))\n",
    "\n",
    "# Make a copy\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Check dtypes\n",
    "print_title('INITIAL DATA TYPES')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_columns(df, datetime_columns=[], int64_columns=[], float64_columns=[], str_columns=[]):\n",
    "    for col in datetime_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    for col in int64_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('Int64')  \n",
    "\n",
    "    for col in float64_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('float64')\n",
    "\n",
    "    for col in str_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns = ['WHEN_ENTERED_INTO_EXPERIMENT']\n",
    "int64_columns = ['U_ID', 'PROMOTER_U_ID', 'IS_TREATMENT', 'COUNT_TRANSFERS', 'DAYS_TRANSACTING', 'DISTINCT_RECEIVERS']\n",
    "float64_columns = ['TOTAL_TRANSFER_AMOUNT']\n",
    "str_columns = ['VARIANT', 'USER_SEGMENT', 'PROMO_TAG']\n",
    "\n",
    "# Basic data conversion\n",
    "df = format_columns(df, datetime_columns, int64_columns, float64_columns, str_columns)\n",
    "\n",
    "# Check dtypes\n",
    "print_title('CONVERTED DATA TYPES')\n",
    "print(df.dtypes)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_column = 'VARIANT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick checks on data\n",
    "print_title('DF INFO')\n",
    "display(df.info())\n",
    "\n",
    "print_title('DF DESCRIBE')\n",
    "display(df.describe())\n",
    "\n",
    "# Check distribution of variants\n",
    "print_title('VARIANT DISTRIBUTION')\n",
    "display(df[variant_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and drop duplicates in the entire DataFrame\n",
    "duplicated_rows = df.duplicated().sum()\n",
    "print('# of duplicated rows: ', duplicated_rows)\n",
    "\n",
    "if duplicated_rows > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print('Duplicates in the DataFrame removed.')\n",
    "else:\n",
    "    print('No duplicates in the DataFrame found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key_column = 'U_ID'\n",
    "timestamp_column = ''\n",
    "\n",
    "# Check for duplicates in the unique columns\n",
    "duplicated_rows = df[df[primary_key_column].duplicated(keep=False)]\n",
    "print(f'# of duplicated on {primary_key_column} column: {duplicated_rows[primary_key_column].nunique()}')\n",
    "\n",
    "if not duplicated_rows.empty:\n",
    "    print(f'Duplicated {primary_key_column} and their rows:')\n",
    "    display(duplicated_rows.sort_values(by = 'U_ID'))\n",
    "\n",
    "    # Keep only the first following timestamp column order\n",
    "    if timestamp_column == '':\n",
    "        df = df.drop_duplicates(subset=primary_key_column, keep='last')\n",
    "        print('Kept the most recent row for each duplicated U_ID.')\n",
    "    else:\n",
    "        df = df.sort_values(timestamp_column).drop_duplicates(subset=primary_key_column, keep='last')\n",
    "        print('Kept the most recent row for each duplicated U_ID.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NULLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print_title('NUMBER OF NULL VALUES')\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null columns\n",
    "df['TOTAL_TRANSFER_AMOUNT'] = df['TOTAL_TRANSFER_AMOUNT'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INCONSISTENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks errors in variant labeling\n",
    "checks = df[(df['IS_TREATMENT'] == 1) & (df['VARIANT'] != 'PRICE_PROMO')]\n",
    "display(checks)\n",
    "checks = df[(df['IS_TREATMENT'] == 0) & (df['VARIANT'] != 'CONTROL')]\n",
    "display(checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics, use metric_cnt_ or metric_cvr_\n",
    "df['metric_cnt_total_transfer_amount'] = df['TOTAL_TRANSFER_AMOUNT']\n",
    "df['metric_cvr_transaction'] = df['TOTAL_TRANSFER_AMOUNT'].apply(lambda x: 1 if x > 0 else 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select metrics and columns involved in the test\n",
    "metric = 'metric_cvr_transaction'\n",
    "variant_column = 'VARIANT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUMBER OF VARIANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Variants: 2\n",
      "Variants: ['CONTROL' 'PRICE_PROMO']\n"
     ]
    }
   ],
   "source": [
    "num_variants = df[variant_column].nunique()\n",
    "variant_values = df[variant_column].unique()\n",
    "\n",
    "print(f\"Number of Variants: {num_variants}\")\n",
    "print(f\"Variants: {variant_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes per variant:\n",
      "VARIANT\n",
      "CONTROL        29450\n",
      "PRICE_PROMO    16166\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportion per variant:\n",
      "VARIANT\n",
      "CONTROL        0.645607\n",
      "PRICE_PROMO    0.354393\n",
      "Name: count, dtype: float64\n",
      "\n",
      "Variant Ratio (N = max/min): 1.82\n"
     ]
    }
   ],
   "source": [
    "# check if the sample size is large enough\n",
    "# check if the variant sizes ar equal or not and the proportion\n",
    "\n",
    "sample_sizes = df[variant_column].value_counts()\n",
    "print(\"Sample sizes per variant:\")\n",
    "print(sample_sizes)\n",
    "\n",
    "variant_proportion = sample_sizes / sample_sizes.sum()\n",
    "print(\"\\nProportion per variant:\")\n",
    "print(variant_proportion)\n",
    "\n",
    "variant_ratio = sample_sizes.max() / sample_sizes.min()\n",
    "print(f\"\\nVariant Ratio (N = max/min): {variant_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the distribution is normal or not\n",
    "\n",
    "# add q plots, histogram and violin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE VARIANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the variances are similar between variantes\n",
    "# add boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATISTICAL TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST AND TECHNICHES SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two variants tests\n",
    "use_mann_whitney_u_test = False # continuous, not normal, works with unbalanced samples\n",
    "use_welchs_t_test = False # continuous, normal, different variances, works with unbalanced samples (if low unbalance applied although same variants)\n",
    "use_t_test = False # continuous, normal, equal variances, not recommended if unbalanced\n",
    "use_z_test = False # continuous data, large sample size, known population real variance, not recommended if unbalanced, not used because you never know the real variance\n",
    "use_fisher_exact_test = False # proportions, small sample size, works with unbalanced samples, # for proportions, only size matters due to central limit theorem\n",
    "use_two_proportion_z_test = False # proportions, large sample size, works with unbalanced samples, used alone or post Pearson Chi-square with Bonferroni for multiple variants, # for proportions, only size matters due to central limit theorem\n",
    "\n",
    "## Multiple variants tests\n",
    "use_anova_test = False # continuous, normal, not recommended if unbalanced\n",
    "use_welch_anova_test = False # continuous, normal, if unbalanced\n",
    "use_pearson_chi_square_test = False # proportions, works with unbalanced samples but needs correction\n",
    "use_kruskal_wallis_test = False # continuous, not normal, works with unbalanced samples\n",
    "\n",
    "## Multiple variants post-pairs tests\n",
    "use_tukey_hsd_test = False # post anova, continuous, not recommended if unbalanced\n",
    "use_games_howell_test = False # post anova, continuous, for unbalanced samples\n",
    "use_dunn_test = False # post kruskal wallis, continuous, needs bonferroni, works with unbalanced samples\n",
    "\n",
    "## Multiple variants correction\n",
    "use_bonferroni_correction = False # if more than 2 variants and tukey pr games howell is not used\n",
    "\n",
    "## Unbalance data: N = A/B, if N < 2.5 use normal testing, if N < 5x use balance resampling, if N > 5x use bootstraping\n",
    "use_balance_resampling = False # for unbalanced sample sizes, equalizing groups, downsampling,\n",
    "use_bootstraping = False # for small sample sizes or unbalanced groups, estimating confidence intervals, upsampling,\n",
    "\n",
    "## Additional techniques\n",
    "use_bayesian_test = False # for probabilistic interpretation, alternative to p-values, small samples\n",
    "use_permutation_test = False # for distribution-free significance testing, alternative to t-tests or z-tests, extrange distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Segmentation\n",
    "use_welchs_t_test_segmentation = False # for comparing two segments (A-New vs. B-New), continuous, normal, can unbalanced\n",
    "use_mann_whitney_u_test_segmentation = False # for comparing two segments (A-New vs. B-New), continuous, not normal, can unbalanced\n",
    "use_two_proportion_z_test_segmentation = False # for comparing two segments (A-New vs. B-New), proportions, large sample\n",
    "use_fisher_exact_test_segmentation = False # for comparing two segments (A-New vs. B-New), proportions, small sample\n",
    "\n",
    "## Interaction Tests, if discrepancies between segments\n",
    "use_anova_interaction_test_segmentation = False # to test interaction effect between variant and segment, continuous, normal\n",
    "use_welch_anova_interaction_test_segmentation = False # to test interaction effect between variant and segment, continuous, normal, can unbalanced\n",
    "use_kruskal_wallis_interaction_test_segmentation = False # to test interaction effect between variant and segment, continuous, not normal\n",
    "use_logistic_regression_interaction_test_segmentation = False # to test interaction effect for proportions, equivalent to ANOVA for categorical data\n",
    "# if true, post hoc with tukey, games howell or dunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNBALANCE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BALANCE RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOTSTRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDITIONAL TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BAYESIAN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PERMUTATION TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEGMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
